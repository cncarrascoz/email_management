{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../../requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c56ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re, html\n",
    "from email import policy\n",
    "from email.parser import Parser\n",
    "from bs4 import BeautifulSoup \n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb640993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/emails.csv\")\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[22,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11373f02",
   "metadata": {},
   "source": [
    "The message columns clearly have a lot of information, let's parse and clean them before doing any further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd394be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# -------- layer 1: header clean‑up --------\n",
    "_SPLIT_KEYS = [\n",
    "    'Message-ID: ', 'Date: ', 'From: ', 'To: ', 'Subject: ', 'Cc: ',\n",
    "    'Mime-Version: ', 'Content-Type: ', 'Content-Transfer-Encoding: ',\n",
    "    'Bcc: ', 'X-From: ', 'X-To: ', 'X-cc: ', 'X-bcc: ', 'X-Folder: ',\n",
    "    'X-Origin: ', 'X-FileName: '\n",
    "]\n",
    "_SPLIT_PATTERN = '|'.join(_SPLIT_KEYS)\n",
    "\n",
    "def clean_headers(raw_msg: str) -> str:\n",
    "    \"\"\"\n",
    "    1) Remove header duplicates that break splitting\n",
    "    2) Ensure all 18 keys exist (add blank 'To:' if missing)\n",
    "    Returns a repaired RFC‑822 string.\n",
    "    \"\"\"\n",
    "    txt = (\n",
    "        raw_msg\n",
    "        .replace(' Date: ',    ' Date- ')     # duplicate tokens\n",
    "        .replace(' Subject: ', ' Subject2: ')\n",
    "        .replace(' To: ',      ' To- ')\n",
    "        .replace(' (Subject: ',' (Subject- ')\n",
    "    )\n",
    "    # Add a blank 'To:' line for messages that go From -> Subject directly\n",
    "    if re.search(r'\\nSubject: ', txt) and not re.search(r'\\nTo: ', txt):\n",
    "        txt = txt.replace('\\nSubject: ', '\\nTo: \\nSubject: ')\n",
    "\n",
    "    # Add a blank 'Cc:' line for messages that go From -> To -> Subject directly\n",
    "    if re.search(r'\\nTo: ', txt) and not re.search(r'\\nCc: ', txt):\n",
    "        txt = txt.replace('\\nTo: ', '\\nCc: \\nTo: ')\n",
    "    \n",
    "    # Add a blank 'Bcc:' line for messages that go From -> To -> Cc -> Subject directly\n",
    "    if re.search(r'\\nCc: ', txt) and not re.search(r'\\nBcc: ', txt):\n",
    "        txt = txt.replace('\\nCc: ', '\\nBcc: \\nCc: ')\n",
    "    \n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- layer 2: clean the BODY ---------------------------------\n",
    "SIG_RE   = re.compile(r'(?m)^\\s*--\\s*$')                                 # “-- ” sig separator\n",
    "FWD_RE = re.compile(\n",
    "    r\"\"\"(?imx)                     # i: ignore‑case, m: ^$ per‑line, x: verbose\n",
    "    ^\\s*-{2,}\\s*                   # line starts with ≥2 dashes\n",
    "    (?:                            # non‑capturing group\n",
    "         forwarded\\s+message       # “Forwarded message”\n",
    "       | forwarded\\s+by            # “Forwarded by …”\n",
    "       | original\\s+message        # “Original Message”\n",
    "    )\n",
    "    .*?$                           # rest of line\n",
    "    \"\"\"\n",
    ")\n",
    "QUOTE_RE = re.compile(r'(?m)^\\s*>.*$')                                   # quoted reply lines\n",
    "\n",
    "def drop_html(raw: str) -> str:\n",
    "    \"\"\"Strip HTML tags and decode HTML entities.\"\"\"\n",
    "    soup = BeautifulSoup(raw, \"lxml\")\n",
    "    return soup.get_text(\" \", strip=True)\n",
    "\n",
    "def clean_content(body: str) -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dict with:\n",
    "      clean_body       : purified main text (no quoted replies, sigs, forwards, HTML)\n",
    "      forward_tail     : text from the first forwarded‑chain marker onward (may be '')\n",
    "      has_other_content: True if attachment/banner separator '-------------' seen\n",
    "      is_forwarded     : True if FWD_RE matched (forward chain existed)\n",
    "    \"\"\"\n",
    "    # 1️⃣ split on first forward marker\n",
    "    m = FWD_RE.search(body)\n",
    "    if m:\n",
    "        body_main  = body[:m.start()]\n",
    "        forward_tail = body[m.start():]\n",
    "        is_fwd = True\n",
    "    else:\n",
    "        body_main  = body\n",
    "        forward_tail = \"\"\n",
    "        is_fwd = False\n",
    "\n",
    "    # 2️⃣ now handle banners *inside the main part only*\n",
    "    has_other = \"-------------\" in body_main\n",
    "    if has_other:\n",
    "        body_main = body_main.split(\"-------------\", 1)[0]\n",
    "\n",
    "    # -- 2) strip HTML from both parts ------------------------\n",
    "    body_main  = drop_html(body_main)\n",
    "    forward_tail = drop_html(forward_tail)\n",
    "\n",
    "    # -- 3) remove quoted replies & signatures ----------------\n",
    "    body_main = QUOTE_RE.sub(\"\", body_main)\n",
    "    body_main = SIG_RE.split(body_main)[0]\n",
    "\n",
    "    # -- 4) normalise whitespace & entities -------------------\n",
    "    body_main = html.unescape(body_main)\n",
    "    body_main = re.sub(r\"\\s+\", \" \", body_main).strip()\n",
    "\n",
    "    forward_tail = html.unescape(forward_tail)\n",
    "    forward_tail = re.sub(r\"\\s+\", \" \", forward_tail).strip()\n",
    "\n",
    "    return {\n",
    "        \"clean_body\": body_main,\n",
    "        # \"forward_tail\": forward_tail,      # re-include later for future experiments\n",
    "        \"has_other_content\": has_other,\n",
    "        \"is_forwarded\": is_fwd\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a06d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Parser(policy=policy.default)\n",
    "\n",
    "def parse_email(raw_msg: str) -> dict:\n",
    "    # header repair ➜ parse\n",
    "    msg = parser.parsestr(clean_headers(raw_msg))\n",
    "\n",
    "    body_text = next(\n",
    "        (part.get_payload(decode=True).decode(errors='ignore')\n",
    "         for part in (msg.walk() if msg.is_multipart() else [msg])\n",
    "         if part.get_content_type() == 'text/plain'),\n",
    "        ''\n",
    "    )\n",
    "\n",
    "    cleaned = clean_content(body_text)\n",
    "\n",
    "    return {\n",
    "        \"from\":   msg[\"from\"],  \"to\": msg[\"to\"],     \"cc\":  msg[\"cc\"],\n",
    "        \"bcc\":    msg[\"bcc\"],   \"subject\": msg[\"subject\"],\n",
    "        \"date\":   msg[\"date\"],  \"msg_id\": msg[\"message-id\"],\n",
    "        **cleaned\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = df['message'].apply(parse_email)\n",
    "parsed_df = pd.DataFrame(parsed.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5859a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df.info()\n",
    "parsed_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167ad9e",
   "metadata": {},
   "source": [
    "There are 3 emails that still arent formatted like the others, let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d7bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = parsed_df[parsed_df[\"to\"].notna()]\n",
    "parsed_df = parsed_df[parsed_df[\"cc\"].notna()]\n",
    "parsed_df = parsed_df[parsed_df[\"bcc\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df.info()\n",
    "parsed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87481dbf",
   "metadata": {},
   "source": [
    "Great! Now we have a cleaned DataFrame with the parsed email data. Let's keep exploring the data further and then apply it to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c30001",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df['from'].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753672c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df['to'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534eb53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'date' is converted to datetime before using .dt accessor\n",
    "if not pd.api.types.is_datetime64_any_dtype(parsed_df['date']):\n",
    "\tparsed_df['date'] = pd.to_datetime(parsed_df['date'], errors='coerce')\n",
    "# parsed_df['year_month'] = parsed_df['date'].dt.to_period('M')\n",
    "# parsed_df['year_month'].value_counts().sort_index().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa6a62f",
   "metadata": {},
   "source": [
    "The data looks clean enough, lets export it in chunks for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca674ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_iter = pd.read_csv(\n",
    "    \"../data/raw/emails.csv\",\n",
    "    usecols=['message'],\n",
    "    chunksize=25000\n",
    ")\n",
    "for i, chunk in enumerate(chunk_iter):\n",
    "    parsed = chunk['message'].apply(parse_email)\n",
    "    parsed_df = pd.DataFrame(parsed.tolist())\n",
    "\n",
    "    parsed_df = parsed_df[parsed_df[\"to\"].notna()]\n",
    "    parsed_df = parsed_df[parsed_df[\"cc\"].notna()]\n",
    "    parsed_df = parsed_df[parsed_df[\"bcc\"].notna()]\n",
    "    \n",
    "    if not pd.api.types.is_datetime64_any_dtype(parsed_df['date']):\n",
    "        parsed_df['date'] = pd.to_datetime(parsed_df['date'], errors='coerce')\n",
    "\n",
    "    parsed_df.to_parquet(\n",
    "        f\"../data/interim/cleaned_emails_part{i:03d}.parquet\",\n",
    "        index=False\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
